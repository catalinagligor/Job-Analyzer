import streamlit as st
import os
import re
import requests
import pandas as pd
import json
from bs4 import BeautifulSoup
from typing import List, Optional, Literal
from pydantic import BaseModel, Field
import instructor
from groq import Groq
from dotenv import load_dotenv


# ==============================================================================
# 1. SETUP & SECURITATE
# ==============================================================================
st.set_page_config(page_title="GenAI Headhunter", page_icon="üïµÔ∏è", layout="wide")

# √éncƒÉrcƒÉm variabilele din fi»ôierul .env
load_dotenv()

# √éncercƒÉm sƒÉ luƒÉm cheia din OS (local) sau din Streamlit Secrets (cloud)
api_key = os.getenv("GROQ_API_KEY")

# Fallback pentru Streamlit Cloud deployment
if not api_key and "GROQ_API_KEY" in st.secrets:
    api_key = st.secrets["GROQ_API_KEY"]

# Validare criticƒÉ: DacƒÉ nu avem cheie, oprim aplica»õia aici.
if not api_key:
    st.error("‚õî EROARE CRITICƒÇ: Lipse»ôte `GROQ_API_KEY`.")
    st.info("Te rog creeazƒÉ un fi»ôier `.env` √Æn folderul proiectului »ôi adaugƒÉ: GROQ_API_KEY=cheia_ta_aici")
    st.stop()


# Configurare Client Groq Global (pentru a nu-l reini»õializa constant)
client = instructor.from_groq(Groq(api_key=api_key), mode=instructor.Mode.TOOLS)

extractor_client = instructor.from_groq(Groq(api_key=api_key),mode=instructor.Mode.TOOLS)

counselor_client = instructor.from_groq(Groq(api_key=api_key),mode=instructor.Mode.TOOLS)

# Sidebar Informativ (FƒÉrƒÉ input de date sensibile)
with st.sidebar:
    st.header("üïµÔ∏è GenAI Headhunter")
    st.success("‚úÖ API Key √ÆncƒÉrcat securizat")
    st.markdown("---")
    st.write("Acest tool demonstreazƒÉ:")
    st.write("‚Ä¢ Web Scraping (BS4)")
    st.write("‚Ä¢ Secure Env Variables")
    st.write("‚Ä¢ Structured Data (Pydantic)")


# ==============================================================================
# 2. DATA MODELS (PYDANTIC SCHEMAS)
# ==============================================================================
class SalaryRange(BaseModel):
    min: int = Field(..., ge=0, description="Salariul minim")
    max: int = Field(..., ge=0, description="Salariul maxim")
    currency: str = Field(..., description="Moneda (ex: RON, USD, EUR, CHF)")

class Location(BaseModel):
    city: str = Field(..., description="Ora»ô")
    country: str = Field(..., description="»öarƒÉ")
    is_remote: bool = Field(..., description="True dacƒÉ jobul este remote/hibrid")

class RedFlag(BaseModel):
    severity: Literal["low", "medium", "high"] = Field(..., description="Severitatea semnalului")
    category: Literal["toxicity", "vague", "unrealistic"] = Field(..., description="Categoria semnalului")
    message: str = Field(..., description="Descrierea semnalului de alarmƒÉ")

class JobAnalysis(BaseModel):
    role_title: str = Field(..., description="Titlul jobului standardizat")
    company_name: str = Field(..., description="Numele companiei")
    seniority: Literal["Intern", "Junior", "Mid", "Senior", "Lead", "Architect"] = Field(..., description="Nivelul de experien»õƒÉ dedus")
    match_score: int = Field(..., ge=0, le=100, description="Scor 0-100: Calitatea descrierii jobului")
    tech_stack: List[str] = Field(..., description="ListƒÉ cu tehnologii specifice (ex: Python, AWS, React)")
    
    red_flags: List[RedFlag] = Field(..., description="Lista de semnale de alarma")

    summary: str = Field(..., description="Un rezumat scurt al rolului (max 2 fraze) √Æn limba rom√¢nƒÉ")

    salary_range: Optional[SalaryRange] = Field(None, description="Interval salarial dacƒÉ este men»õionat")

    location: Location = Field(..., description="Loca»õia jobului")


class Benefit(BaseModel):
    name: str = Field(..., description="Numele beneficiului")
    details: Optional[str] = Field(None, description="Detalii scurte, dacƒÉ existƒÉ")

class Requirement(BaseModel):
    category: Literal["must_have", "nice_to_have", "other"] = Field(..., description="Tip cerin»õƒÉ")
    text: str = Field(..., description="Cerin»õa, formulatƒÉ concis")

class RawExtraction(BaseModel):
    role_title: Optional[str] = Field(None, description="Titlul rolului")
    company_name: Optional[str] = Field(None, description="Compania")

    tech_stack: List[str] = Field(default_factory=list, description="Tehnologii detectate")
    salary_range: Optional[SalaryRange] = Field(None, description="Interval salarial dacƒÉ existƒÉ")
    benefits: List[Benefit] = Field(default_factory=list, description="Beneficii")
    requirements: List[Requirement] = Field(default_factory=list, description="Cerin»õe")
    location: Optional[Location] = Field(None, description="Loca»õie ")

    confidence: int = Field(80, ge=0, le=100, description="√éncredere √Æn extrac»õie (0-100)")


class StrategicAdvice(BaseModel):
    match_score: int = Field(..., ge=0, le=100, description="Potrivire cu pia»õa/rolul (0-100)")
    market_positioning: str = Field(..., description="Cum se pozi»õioneazƒÉ rolul pe pia»õƒÉ (2-5 fraze)")
    interview_questions: List[str] = Field(..., description="√éntrebƒÉri strategice pentru interviu (5-10)")
    negotiation_tips: List[str] = Field(..., description="Sfaturi de negociere (3-6)")
    red_flags: List[RedFlag] = Field(default_factory=list, description="Red flags deduse din facts")
    summary: str = Field(..., description="Rezumat scurt √Æn limba rom√¢nƒÉ (max 2 fraze)")

# ==============================================================================
# 3. UTILS - SCRAPER (Colectare Date)
# ==============================================================================

def scrape_clean_job_text(url: str, max_chars: int = 3000) -> str:
    """
    DescarcƒÉ pagina »ôi returneazƒÉ un text curat, optimizat pentru contextul LLM.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            return f"Error: Status code {response.status_code}"
            
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # EliminƒÉm elementele inutile care consumƒÉ tokeni
        for junk in soup(["script", "style", "nav", "footer", "header", "aside", "iframe"]):
            junk.decompose()
            
        # Extragem textul »ôi eliminƒÉm spa»õiile multiple
        text = soup.get_text(separator=' ', strip=True)
        text = re.sub(r'\s+', ' ', text)
        
        return text[:max_chars] 
        
    except Exception as e:
        return f"Scraping Error: {str(e)}"

# ==============================================================================
# 4. AI SERVICE LAYER (Logica LLM)
# ==============================================================================

def analyze_job_with_ai(text: str) -> JobAnalysis:
    """
    Trimite textul curƒÉ»õat cƒÉtre Groq »ôi returneazƒÉ obiectul structurat.
    """
    return client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        response_model=JobAnalysis,
        messages=[
            {
                "role": "system", 
                "content": (
                    "E»ôti un Recruiter Expert √Æn IT. AnalizeazƒÉ textul jobului cu obiectivitate. "
                    "IdentificƒÉ tehnologiile »ôi poten»õialele probleme (red flags). "
                    "Pentru salary_range: daca nu exista salariul, afiseaza null"
                    "Pentru location: alege city »ôi country din context; dacƒÉ nu e clar, pune 'Necunoscut'. "
                    "Pentru red_flags: √Æntoarce o listƒÉ de obiecte cu severity (low/medium/high), category (toxicity/vague/unrealistic) »ôi message scurt."
                    "RƒÉspunde strict √Æn formatul cerut."
                )
            },
            {
                "role": "user", 
                "content": f"AnalizeazƒÉ acest job description:\n\n{text}"
            }
        ],
        temperature=0.1,
    )

def extract_facts_with_ai(text: str) -> RawExtraction:
    return extractor_client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        response_model=RawExtraction,
        messages=[
            {
                "role": "system",
                "content": (
                    "E»ôti The Extractor. Extragi DOAR fapte brute din textul jobului. "
                    "Nu interpreta, nu da sfaturi, nu inventa. "
                    "DacƒÉ o informa»õie nu e √Æn text, las-o null sau listƒÉ goalƒÉ. "
                    "tech_stack: doar tehnologii explicit men»õionate. "
                    "salary_range: doar dacƒÉ existƒÉ valori numerice/interval + monedƒÉ. "
                    "benefits/requirements: extrage exact ce e men»õionat."
                ),
            },
            {
             "role": "user", 
             "content": f"Text job:\n\n{text}"
            
            },
        ],
        temperature=0.0,
    )

def generate_advice_with_ai(facts: RawExtraction) -> StrategicAdvice:

    facts_json = json.dumps(facts.model_dump(), ensure_ascii=False)

    return counselor_client.chat.completions.create(
        model="openai/gpt-oss-20b",
        response_model=StrategicAdvice,
        messages=[
            {
                "role": "system",
                "content": (
                    "E»ôti The Counselor. Prime»ôti FACTE extrase despre un job (JSON) »ôi trebuie sƒÉ returnezi STRICT un obiect "
                    "conform schemei StrategicAdvice. Nu omite niciun c√¢mp.\n\n"

                    "Schema StrategicAdvice are c√¢mpurile OBLIGATORII:\n"
                    "- match_score (int 0-100)\n"
                    "- market_positioning (string)\n"
                    "- interview_questions (list[string])\n"
                    "- negotiation_tips (list[string])\n"
                    "- summary (string, max 2 fraze √Æn rom√¢nƒÉ)\n"
                    "- red_flags (list de obiecte RedFlag)\n\n"

                    "Schema RedFlag (OBLIGATORIU pentru fiecare element din red_flags):\n"
                    "- severity: una din ['low','medium','high']\n"
                    "- category: una din ['toxicity','vague','unrealistic']\n"
                    "- message: text scurt\n\n"

                    "Reguli:\n"
                    "- NU folosi chei precum 'description' sau 'details'. Folose»ôte DOAR 'message'.\n"
                    "- DacƒÉ nu ai red flags, red_flags trebuie sƒÉ fie lista goalƒÉ [].\n"
                    "- DacƒÉ lipsesc informa»õii (salariu/beneficii/cerin»õe/loca»õie), adaugƒÉ cel pu»õin 1 red flag "
                    "cu category='vague' »ôi severity='medium'.\n\n"

                    "Exemplu red_flags corect:\n"
                    "[{\"severity\":\"medium\",\"category\":\"vague\",\"message\":\"Lipsesc detalii despre salariu »ôi beneficii.\"}]"
                ),
            },
            {"role": "user", "content": f"FACTS(JSON):\n{facts_json}"},
        ],
        temperature=0.7,
    )

def analyze_job_pipeline(text: str) -> tuple[RawExtraction, StrategicAdvice]:
    facts = extract_facts_with_ai(text)
    advice = generate_advice_with_ai(facts)
    return facts, advice

# ==============================================================================
# 5. UI - APLICA»öIA STREAMLIT
# ==============================================================================

st.title("üïµÔ∏è GenAI Headhunter Assistant")
st.markdown("TransformƒÉ orice Job Description √Æntr-o analizƒÉ structuratƒÉ folosind AI.")

# Tab-uri
tab1, tab2 = st.tabs(["üöÄ AnalizƒÉ Job", "üìä Market Scan (Batch)"])

# --- TAB 1: ANALIZA UNUI SINGUR LINK ---
with tab1:
    st.subheader("AnalizeazƒÉ un Job URL")
    url_input = st.text_input("Introdu URL-ul:", placeholder="https://...")

    use_multi_agent = st.toggle("üîÅ Level 2: Multi-agent (Extractor + Counselor)", value=False)



    if st.button("AnalizeazƒÉ Job", key="btn_single"):
        if not url_input:
            st.warning("Te rugƒÉm introdu un URL.")
        else:
            with st.spinner("üï∑Ô∏è Scraping & ü§ñ AI Analysis..."):
                raw_text = scrape_clean_job_text(url_input)
            
            if "Error" in raw_text:
                st.error(raw_text)
            else:
                try:
                    data = analyze_job_with_ai(raw_text)
                    
                    # -- DISPLAY --
                    st.divider()
                    col_h1, col_h2 = st.columns([3, 1])
                    with col_h1:
                        st.markdown(f"### {data.role_title}")
                        st.caption(f"Companie: **{data.company_name}** | Nivel: **{data.seniority}**")
                    with col_h2:
                        color = "normal" if data.match_score > 70 else "inverse"
                        st.metric("Quality Score", f"{data.match_score}/100", delta_color=color)

                    # Detalii
                    c1, c2, c3 = st.columns(3)
                    c1.info(f"**Remote:** {'Da' if data.location.is_remote else 'Nu'}")
                    c2.success(f"**Tehnologii:** {len(data.tech_stack)}")
                    c3.error(f"**Red Flags:** {len(data.red_flags)}")


                    if not data.location.is_remote:
                        st.markdown( f"üìç **Loca»õie:** {data.location.city}, {data.location.country}")
                        
                    st.markdown(f"**üìù Rezumat:** {data.summary}")
                    st.markdown("#### üõ†Ô∏è Tech Stack")
                    st.write(", ".join([f"`{tech}`" for tech in data.tech_stack]))

                    if data.red_flags:
                        st.markdown("#### üö© Avertismente")
                        for flag in data.red_flags:
                           st.warning(f"**{flag.severity.upper()} / {flag.category}** ‚Äî {flag.message}")


                    # ==========================
                    # NIVEL 2 (Multi-agent) 
                    # ==========================
                    if use_multi_agent:
                        st.divider()
                        st.markdown("## Multi-agent results")
                        facts, advice = analyze_job_pipeline(raw_text)
                        report = None

                        # 1) Extractor  (facts only)
                    with st.expander("üßæ Extractor (Fapte reale)", expanded=True):
                          # Titlu + companie
                        st.markdown(f"**Rol:** {facts.role_title or 'N/A'}")
                        st.markdown(f"**Companie:** {facts.company_name or 'N/A'}")

                        # Loca»õie
                        if facts.location:
                            if facts.location.is_remote:
                                st.info("Remote / Hybrid")
                            else:
                                st.success(f"üìç {facts.location.city}, {facts.location.country}")

                        # Salariu
                        if facts.salary_range:
                            st.markdown(
                                f"**Salariu:** {facts.salary_range.min} - {facts.salary_range.max} {facts.salary_range.currency}"
                            )
                        else:
                            st.caption("Salariu: nementionat")

                        # Tech stack
                        st.markdown("**Tech stack (facts):**")
                        if facts.tech_stack:
                            st.write(", ".join([f"`{t}`" for t in facts.tech_stack]))
                        else:
                            st.caption("Nu a fost detectatƒÉ tehnologie explicitƒÉ.")

                        # Requirements
                        st.markdown("**Cerin»õe (facts):**")
                        if facts.requirements:
                            must = [r.text for r in facts.requirements if r.category == "must_have"]
                            nice = [r.text for r in facts.requirements if r.category == "nice_to_have"]
                            other = [r.text for r in facts.requirements if r.category == "other"]

                            if must:
                                st.markdown(" **Must-have:**")
                                for x in must:
                                    st.write(f"  - {x}")
                            if nice:
                                st.markdown(" **Nice-to-have:**")
                                for x in nice:
                                    st.write(f"  - {x}")
                            if other:
                                st.markdown("**Altele:**")
                                for x in other:
                                    st.write(f"  - {x}")
                        else:
                            st.caption("Nu sunt cerin»õe clare √Æn text (sau jobul nu mai e disponibil).")

                        # Benefits
                        st.markdown("**Beneficii (facts):**")
                        if facts.benefits:
                            for b in facts.benefits:
                                if b.details:
                                    st.write(f"- {b.name} ‚Äî {b.details}")
                                else:
                                    st.write(f"- {b.name}")
                        else:
                            st.caption("Nu sunt beneficii men»õionate.")


                        # 2) Counselor  (strategic)
                        st.markdown("### üß† Consilier (Sfaturi)")
                        st.metric("Match score", f"{advice.match_score}/100")
                        st.markdown(f"**Rezumat:** {advice.summary}")

                        if advice.red_flags:
                            st.markdown("#### üö© Red Flags (Consilier)")
                            for rf in advice.red_flags:
                                st.warning(f"**{rf.severity.upper()} / {rf.category}** ‚Äî {rf.message}")
                        else:
                            st.success("Nu au fost detectate red flags ( Consilier ).")

                        st.markdown("#### üé§ √éntrebƒÉri de interviu")
                        for q in advice.interview_questions:
                            st.write(f"- {q}")

                        st.markdown("#### üí¨ Sfaturi de negociere")
                        for tip in advice.negotiation_tips:
                            st.write(f"- {tip}")

                except Exception as e:
                    st.error(f"Eroare AI: {str(e)}")

# --- TAB 2: BATCH PROCESSING ---
with tab2:
    st.subheader("üìä ComparƒÉ mai multe joburi")
    urls_text = st.text_area("Paste URL-uri (unul pe linie):", height=150)
    
    if st.button("ScaneazƒÉ Pia»õa", key="btn_batch"):
        urls = [u.strip() for u in urls_text.split('\n') if u.strip()]
        
        if not urls:
            st.warning("Nu ai introdus link-uri.")
        else:
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, link in enumerate(urls):
                status_text.text(f"Analizez {i+1}/{len(urls)}...")
                text = scrape_clean_job_text(link)
                
                if "Error" not in text:
                    try:
                        res = analyze_job_with_ai(text)
                        results.append({
                         "Role": res.role_title,
                         "Company": res.company_name,
                         "Seniority": res.seniority,
                         "Remote": res.location.is_remote,
                         "TechCount": len(res.tech_stack),
                         "RedFlags": len(res.red_flags),
                         "Score": res.match_score
                        })
                    except:
                        pass # ContinuƒÉm chiar dacƒÉ unul crapƒÉ
                
                progress_bar.progress((i + 1) / len(urls))
            
            status_text.text("Gata!")
            
            if results:
                df = pd.DataFrame(results)
                st.dataframe(df)
                
                # Grafic simplu
                st.bar_chart(df['Seniority'].value_counts())